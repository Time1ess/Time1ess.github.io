<!DOCTYPE html><html lang="zh-cn"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> 机器学习算法之监督学习算法KNN(K近邻) · David's Blog</title><meta name="description" content="机器学习算法之监督学习算法KNN(K近邻) - David"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/imgs/favicon.ico"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/bootstrap-theme.css"><link rel="stylesheet" href="/css/apollo.css"><link rel="stylesheet" href="/css/david.css"><link rel="search" type="application/opensearchdescription+xml" href="http://youchen.me/atom.xml" title="David's Blog"><script type="text/x-mathjax-config">MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script><script async type="text/javascript" src="//cdnjs.cloudflare.com/ajax//libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><script src="/js/jquery-3.1.1.min.js"></script><script src="/js/bootstrap.min.js"></script><script src="/js/typeahead.js"></script><script src="/js/search.js"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-89945048-1",'auto');ga('send','pageview');</script><script>(function(){var bp = document.createElement('script');var curProtocol = window.location.protocol.split(':')[0];if (curProtocol === 'https') {bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';}else {bp.src = 'http://push.zhanzhang.baidu.com/push.js';}var s = document.getElementsByTagName("script")[0];s.parentNode.insertBefore(bp, s);})();</script></head><body><div id="search"><div id="search-panel" class="search-panel"><div class="search-input"><input id="search-keywords" type="text" placeholder="搜索范围: 文章标题 日期 标签" class="form-control"><ul role="list" class="typeahead dropdown-menu"></ul></div><div class="search-close"><a id="search-close" href="#"><img src="/imgs/close-white.png"></a></div></div><div class="search-button"><a id="search-open" title="双击Ctrl快速打开搜索框"><img src="/imgs/search-black.png"></a></div></div><div class="apollo-wrap"><header class="apollo"><a href="/" class="logo-link"><img src="/imgs/favicon.png" alt="logo"></a><ul class="apollo-nav apollo-nav-list"><li class="apollo-nav-list-item"><a href="/" target="_self" class="apollo-nav-list-link">博客</a></li><li class="apollo-nav-list-item"><a href="/archives" target="_self" class="apollo-nav-list-link">归档</a></li><li class="apollo-nav-list-item"><a href="/categories" target="_self" class="apollo-nav-list-link">分类</a></li><li class="apollo-nav-list-item"><a href="https://github.com/Time1ess" target="_blank" class="apollo-nav-list-link">GITHUB</a></li><li class="apollo-nav-list-item"><a href="/atom.xml" target="_self" class="apollo-nav-list-link">RSS</a></li><li class="apollo-nav-list-item"><a href="/about" target="_self" class="apollo-nav-list-link">关于</a></li></ul></header><main class="apollo-container"><div class="post"><article class="post-block"><h1 class="post-title">机器学习算法之监督学习算法KNN(K近邻)</h1><div class="post-info">时间: 2017年10月22日 22:07 标签: <a class="tags" href="/tags/机器学习/">#机器学习</a>,<a class="tags" href="/tags/KNN/">#KNN</a>,<a class="tags" href="/tags/监督学习/">#监督学习</a></div><div class="post-content"><p>今天在学院论坛里面写了关于KNN的一篇解释，顺手就转到自己博客了，毕竟这都又是3个月没更新了，感觉自己学了很多但是就是太懒，不想记下来，这个习惯还是得改改。</p>
<a id="more"></a>
<h2 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h2><p>首先是原始代码，已经写好非核心代码，只需要补充<code>L1</code>、<code>L2</code>、<code>knn</code>三个函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python3</span></span><br><span class="line"><span class="comment"># coding: UTF-8</span></span><br><span class="line"><span class="comment"># Author: David</span></span><br><span class="line"><span class="comment"># Email: youchen.du@gmail.com</span></span><br><span class="line"><span class="comment"># Created: 2017-10-21 13:06</span></span><br><span class="line"><span class="comment"># Last modified: 2017-10-21 13:53</span></span><br><span class="line"><span class="comment"># Filename: knn.py</span></span><br><span class="line"><span class="comment"># Description:</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># ===============================================</span></span><br><span class="line"><span class="comment"># For reproducibility, DO NOT CHANGE THIS SECTION</span></span><br><span class="line">np.random.seed(<span class="number">1111</span>)</span><br><span class="line"></span><br><span class="line">M1 = <span class="number">500</span></span><br><span class="line">M2 = <span class="number">50</span></span><br><span class="line">N = <span class="number">1024</span></span><br><span class="line">S = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">train_x = S * np.random.randn(M1, N)</span><br><span class="line">train_y = np.random.randint(<span class="number">0</span>, <span class="number">10</span>, M1)</span><br><span class="line">test_x = S * np.random.randn(M2, N)</span><br><span class="line">target_l1_y = [</span><br><span class="line">    <span class="number">4</span>, <span class="number">4</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">9</span>, <span class="number">5</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">9</span>, <span class="number">4</span>,</span><br><span class="line">    <span class="number">4</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">5</span>, <span class="number">9</span>, <span class="number">7</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">0</span>,</span><br><span class="line">    <span class="number">9</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">4</span>,</span><br><span class="line">    <span class="number">1</span>, <span class="number">9</span>, <span class="number">8</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">7</span>, <span class="number">3</span>,</span><br><span class="line">    <span class="number">1</span>, <span class="number">9</span>]</span><br><span class="line">target_l2_y = [</span><br><span class="line">    <span class="number">5</span>, <span class="number">4</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">9</span>, <span class="number">3</span>,</span><br><span class="line">    <span class="number">9</span>, <span class="number">1</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">9</span>, <span class="number">7</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">0</span>,</span><br><span class="line">    <span class="number">9</span>, <span class="number">3</span>, <span class="number">9</span>, <span class="number">2</span>, <span class="number">9</span>, <span class="number">7</span>, <span class="number">2</span>, <span class="number">8</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>,</span><br><span class="line">    <span class="number">1</span>, <span class="number">1</span>, <span class="number">9</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">9</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">9</span>, <span class="number">6</span>,</span><br><span class="line">    <span class="number">1</span>, <span class="number">5</span>]</span><br><span class="line"><span class="comment"># ==============================================</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">L1</span><span class="params">(x1, x2)</span>:</span></span><br><span class="line">    <span class="comment"># ===================</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> Calculate the L1 distance between x1 and x2.</span></span><br><span class="line">    <span class="comment"># Your code goes here</span></span><br><span class="line">    <span class="comment"># L1 distance</span></span><br><span class="line">    <span class="comment"># ===================</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">L2</span><span class="params">(x1, x2)</span>:</span></span><br><span class="line">    <span class="comment"># ===================</span></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> Calculate the L2 distance between x1 and x2.</span></span><br><span class="line">    <span class="comment"># Your code goes here</span></span><br><span class="line">    <span class="comment"># L2 distance</span></span><br><span class="line">    <span class="comment"># ===================</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">knn</span><span class="params">(train_x, train_y, test_x, sim_func=None, K=<span class="number">10</span>)</span>:</span></span><br><span class="line">    <span class="keyword">assert</span> sim_func <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span></span><br><span class="line">    test_y = np.zeros(M2).astype(int)</span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span></span></span><br><span class="line">    <span class="comment"># Instructions:</span></span><br><span class="line">    <span class="comment"># 1. For each sample(x1) in test_x</span></span><br><span class="line">    <span class="comment"># 2. Calculate similarity between each sample in train_x and x1</span></span><br><span class="line">    <span class="comment"># 3. Using the K nearest neighbors to vote for x1</span></span><br><span class="line">    <span class="comment"># 4. assign y1 to test_y[idx]</span></span><br><span class="line">    <span class="comment"># -----------</span></span><br><span class="line">    <span class="comment"># Please Note test_y is a numpy vector, For i-th example in test_x, you</span></span><br><span class="line">    <span class="comment"># can do like this:</span></span><br><span class="line">    <span class="comment"># test_y[i] = yi</span></span><br><span class="line">    <span class="comment"># ===================</span></span><br><span class="line">    <span class="comment"># Your code goes here</span></span><br><span class="line">    <span class="comment"># ===================</span></span><br><span class="line">    <span class="keyword">return</span> test_y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuracy</span><span class="params">(output, target)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.count_nonzero(np.equal(output, target)) / len(output)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span><span class="params">(func, target)</span>:</span></span><br><span class="line">    print(<span class="string">'Evaluating with your implementation of '</span></span><br><span class="line">          <span class="string">'&#123;&#125; distance'</span>.format(func.__name__))</span><br><span class="line">    test_y = knn(train_x, train_y, test_x, func)</span><br><span class="line">    acc = accuracy(test_y, target)</span><br><span class="line">    print(<span class="string">'Accuracy: &#123;:.2%&#125;'</span>.format(acc))</span><br><span class="line">    <span class="keyword">if</span> np.abs(acc - <span class="number">1</span>) &lt; <span class="number">1e-5</span>:</span><br><span class="line">        print(<span class="string">'Conguratulations, Your implementation is correct'</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">'There are some bugs in your implementation, Please check again'</span>)</span><br><span class="line">    print()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    evaluate(L1, target_l1_y)</span><br><span class="line">    evaluate(L2, target_l2_y)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<p>有几点需要注意(对首次接触Python的人):</p>
<ul>
<li>Python中以<code>#</code>开头的行都是注释，不对程序产生任何影响</li>
<li>与C不同，Python是一门解释型语言，所以大家如果执行一个<code>.py</code>文件，解释器会从上到下依次执行语句，如果<code>.py</code>文件中只包含了类似<code>def func(x)</code>的定义代码，那么执行该文件仅会定义这些函数然后退出，所以如果<code>.py</code>文件里面有需要执行的语句，比如使用<code>print</code>打印一些内容，则可以直接像这么写:</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 该段代码首先定义了一个`hello`函数，该函数接收一个参数`name`，</span></span><br><span class="line"><span class="comment"># 然后函数的作用是打印'hello, &lt;name&gt;'，最后执行`hello`函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hello</span><span class="params">(name)</span>:</span></span><br><span class="line">    print(<span class="string">'hello'</span>, name)</span><br><span class="line"></span><br><span class="line">hello(<span class="string">'david'</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>另外，直接执行一个<code>.py</code>文件时，被执行文件的<code>if __name__ == &#39;__main__&#39;:</code>判断将会为真，在该示例中即会调用<code>main</code>函数。</li>
</ul>
<p>以上是需要注意的几点，具体的Python的语法由于篇幅关系，不再赘述。</p>
<h2 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h2><p>KNN，即K近邻，是一个监督学习算法，算法本身并不复杂，其基本流程是:</p>
<ol>
<li>假设给定包含$ M $个样本的训练集$ X_{train} $，每个样本包含$ N $个特征，以及对应的类别标签$ Y_{train} $，则$ X_{train} $可以用一个$ M \times N $的二维矩阵表示, $ Y_{train} $可以用一个$ M \times 1 $的二维矩阵表示</li>
</ol>
<p>$$<br>X_{train} = \begin{bmatrix}<br>X_1^0 &amp; X_1^1 &amp;  … &amp;  X_1^n \\<br>X_2^0 &amp; X_2^1 &amp;  … &amp;  X_2^n \\<br>… &amp; … &amp; … &amp; … \\<br>X_M^0 &amp; X_M^1 &amp;  … &amp;  X_M^n \\<br>\end{bmatrix}<br>Y_{train} = \begin{bmatrix}<br>Y_0 \\ Y_1 \\ … \\ Y_M<br>\end{bmatrix}<br>$$</p>
<ol>
<li>对于一个需要计算的新样本$ X $，计算其类别：<ol>
<li>计算该样本$ X $与训练集$ X_{train} $中每个样本$ X_i $的距离$ D_i $(不同距离函数计算的距离不同，因此效果也会不同)</li>
<li>在所有距离中取距离最小的前$ K $个样本的类别标签，根据$ K $个标签中出现次数最多的标签来确定样本$ X $的标签</li>
</ol>
</li>
</ol>
<h2 id="距离函数"><a href="#距离函数" class="headerlink" title="距离函数"></a>距离函数</h2><p>首先我们需要定义一些距离函数来衡量两个样本特征之间的相似度，常用的有L1距离、L2距离等。</p>
<h3 id="L1-distance"><a href="#L1-distance" class="headerlink" title="L1 distance"></a>L1 distance</h3><p>假设样本$ X_1 $有$ X_1^0, X_1^1, …, X_1^n $特征，其与样本$ X_2 $之间的L1距离可以用以下公式计算:</p>
<p>$$ L1(X_1, X_2) = \left|X_1^0 - X_2^0\right| + \left|X_1^1 - X_2^1\right| + … + \left|X_1^n - X_2^n\right| $$</p>
<p>L1函数代码示例:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">L1</span><span class="params">(x1, x2)</span>:</span></span><br><span class="line">    <span class="comment"># x1和x2都是向量，x1 - x2为每个特征相减</span></span><br><span class="line">    <span class="comment"># np.abs为每个结果求绝对值</span></span><br><span class="line">    <span class="comment"># np.sum将所有绝对值求和</span></span><br><span class="line">    <span class="keyword">return</span> np.sum(np.abs(x1 - x2))</span><br></pre></td></tr></table></figure>
<h3 id="L2-distance"><a href="#L2-distance" class="headerlink" title="L2 distance"></a>L2 distance</h3><p>L2距离即为特征差的平方求和开方，即:</p>
<p>$$ L2(X_1, X_2) = \sqrt{(X_1^0 -  X_2^0)^2 + (X_1^1 -  X_2^1)^2 + … + (X_1^n -  X_2^n)^2} $$</p>
<p>L2函数代码示例:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">L2</span><span class="params">(x1, x2)</span>:</span></span><br><span class="line">    <span class="comment"># (x1 - x2) ** 2 为特征差的平方</span></span><br><span class="line">    <span class="comment"># np.sum进行求和运算</span></span><br><span class="line">    <span class="comment"># np.sqrt进行开方运算</span></span><br><span class="line">    <span class="keyword">return</span> np.sqrt(np.sum((x1 - x2) ** <span class="number">2</span>))</span><br></pre></td></tr></table></figure>
<h2 id="KNN代码"><a href="#KNN代码" class="headerlink" title="KNN代码"></a>KNN代码</h2><p>由于前面已经介绍过KNN的算法流程了，在此处直接给出实现代码(此处的代码并不是最优的，有其他优化方式，有兴趣的可以自己研究)，代码给出了详细注释。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">knn</span><span class="params">(train_x, train_y, test_x, sim_func=None, K=<span class="number">10</span>)</span>:</span></span><br><span class="line">    <span class="comment"># 防御性编程，忽略</span></span><br><span class="line">    <span class="keyword">assert</span> sim_func <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span></span><br><span class="line">    <span class="comment"># 声明结果存储的空间，所有元素初始化为0</span></span><br><span class="line">    test_y = np.zeros(M2).astype(int)</span><br><span class="line">    <span class="comment"># 遍历每一个test_x中的样本，enumerate函数使得在遍历的同时返回其遍历序号，默认idx以0开始</span></span><br><span class="line">    <span class="keyword">for</span> idx, X1 <span class="keyword">in</span> enumerate(test_x):</span><br><span class="line">        <span class="comment"># 我们需要一个列表来存储所有计算的距离值</span></span><br><span class="line">        neighbors = []</span><br><span class="line">        <span class="comment"># 遍历每一个train_x中的样本，zip函数可以对多个序列进行遍历，</span></span><br><span class="line">        <span class="comment"># 因此我们可以很方便的同时得到train_x中的X1的特征以及它对应的标签</span></span><br><span class="line">        <span class="keyword">for</span> X2, Y2 <span class="keyword">in</span> zip(train_x, train_y):</span><br><span class="line">            <span class="comment"># 使用距离函数sim_func计算样本X1和X2的距离dis</span></span><br><span class="line">            dis = sim_func(X1, X2)</span><br><span class="line">            <span class="comment"># 我们将距离和标签以Python元组的形式(dis, Y2)放入前面声明的列表中</span></span><br><span class="line">            neighbors.append((dis, Y2))</span><br><span class="line">        <span class="comment"># 对neighbors列表中的所有元组进行排序，</span></span><br><span class="line">        <span class="comment"># 比较关键字key使用了每个元组中的第0个元素即(dis, Y2)中的dis</span></span><br><span class="line">        <span class="comment"># 这样我们得到了一个dis从小到大排列的列表</span></span><br><span class="line">        neighbors.sort(key=<span class="keyword">lambda</span> x: x[<span class="number">0</span>])</span><br><span class="line">        <span class="comment"># 使用Python的切片功能我们保留neighbors的前K个元素(即dis最小的前K个)</span></span><br><span class="line">        neighbors = neighbors[:K]</span><br><span class="line">        <span class="comment"># 声明一个字典votes</span></span><br><span class="line">        votes = &#123;&#125;</span><br><span class="line">        <span class="comment"># 遍历neighbors中的K个元素</span></span><br><span class="line">        <span class="keyword">for</span> dis, label <span class="keyword">in</span> neighbors:</span><br><span class="line">            <span class="comment"># 如果当前遍历到的标签label不在字典votes中</span></span><br><span class="line">            <span class="comment"># setdefault函数将会将其加入字典中，并将其值置为0</span></span><br><span class="line">            <span class="comment"># 如果标签在label中，setdefault函数不做任何处理</span></span><br><span class="line">            votes.setdefault(label, <span class="number">0</span>)</span><br><span class="line">            <span class="comment"># 标签label计数加1</span></span><br><span class="line">            votes[label] += <span class="number">1</span></span><br><span class="line">        <span class="comment"># votes.items()方法返回一个列表(实际是一个迭代器，可以先忽略)，</span></span><br><span class="line">        <span class="comment"># 其形式为(label, count)，即标签和它出现的次数</span></span><br><span class="line">        <span class="comment"># max函数用来找到这个列表中最大的那个元素(即我们要的出现最多次的元素)</span></span><br><span class="line">        <span class="comment"># 比较关键字在此处为x[1]，即(label, count)中的count</span></span><br><span class="line">        <span class="comment"># 最后max函数返回了一个(label, count)，该对象是出现次数最多的，我们用下标[0]访问即可得到该标签，</span></span><br><span class="line">        <span class="comment"># 最后将该标签赋值给test_y[idx]，完成！</span></span><br><span class="line">        test_y[idx] = max(votes.items(), key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>])[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> test_y</span><br></pre></td></tr></table></figure>
<p>最后保存并执行，即可得到预期结果</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ python3 knn.py</span><br><span class="line">Evaluating with your implementation of L1 distance</span><br><span class="line">Accuracy: 100.00%</span><br><span class="line">Conguratulations, Your implementation is correct</span><br><span class="line"></span><br><span class="line">Evaluating with your implementation of L2 distance</span><br><span class="line">Accuracy: 100.00%</span><br><span class="line">Conguratulations, Your implementation is correct</span><br></pre></td></tr></table></figure>
<p>至此，一个简单的KNN算法工作完毕。</p>
</div></article></div><script src="/js/comments.js"></script></main><footer class="apollo"><div class="paginator"><a href="/2018/01/12/Django中的select-related与prefetch-related/" class="prev">上一篇</a><a href="/2017/07/25/论文笔记-全卷积神经网络-FCN/" class="next">下一篇</a></div><div class="copyright"><p>© 2016 - 2018 <a href="http://youchen.me">David</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div></body></html>